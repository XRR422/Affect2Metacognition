#### Read me

As described in our paper, we made our user study prototype and statistical measurements of facial expressions publicly available on this site.

**For researcher who interested in our work (Data and networks), please sign M-FEI_models_agreement.pdf and contact Xingran Ruan (xruan@ed.ac.uk) for password.**

Here’s a structured description based on the spreadsheet:

Action Units (AUs): The dataset includes mean values and second derivatives for various AUs like AU01, AU02, AU04, etc., which represent different facial muscles involved in expressions. Metrics like AU01_r_mean indicate the average intensity of the brow raiser muscle during a recorded session.

Game and Target: Each record is associated with a game identifier (e.g., g1) and a target event (e.g., t2). This shows the contextual scenario under which the data was recorded.

Duration: This column indicates the duration of the target event, providing insights into how long each facial expression was held or observed.

Subject ID (sub): Each subject is anonymized and identified by a unique code, indicating the group and session they were part of during the study.

Metacognitive Monitoring Performance (mm_class-2): This column categorizes the performance into two classes—correctmmp and presumably incorrectmmp (not shown in the preview but implied by the context). It represents whether the subjects' responses were correct or incorrect in terms of their metacognitive monitoring capabilities.
